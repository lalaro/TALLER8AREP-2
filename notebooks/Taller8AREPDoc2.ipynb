{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44b4bbab-d6c9-42db-9032-04a4031aed43",
   "metadata": {},
   "source": [
    "## Taller 8 AREP 2\n",
    "\n",
    "Antes de empezar, necesitamos instalar LangChain y las dependencias necesarias. Dependiendo del entorno, en este caso usaremos pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0098a115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ab300b",
   "metadata": {},
   "source": [
    "# Cargar Documentos\n",
    "\n",
    "Se pueden cargar documentos desde diferentes formatos. En este caso, usaremos TextLoader para cargar un archivo de texto.\n",
    "1. os.environ[\"LANGSMITH_TRACING\"] = \"true\" ‚Üí Activa el rastreo (tracing) en LangSmith.\n",
    "2. os.environ[\"LANGSMITH_API_KEY\"] = \"...\" ‚Üí Guarda la clave API en una variable de entorno para autenticar el uso de LangSmith."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bf834c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"ac√° va la clave\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd39950",
   "metadata": {},
   "source": [
    "Instala y actualiza LangChain con soporte para OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0394528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU \"langchain[openai]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2227c885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.3.21)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.3.47)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (0.3.18)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\laura\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\laura\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e93509",
   "metadata": {},
   "source": [
    "## Componentes\n",
    "\n",
    "Este c√≥digo configura una API de OpenAI en LangChain:\n",
    "\n",
    "Manejo de variables de entorno ‚Üí Configura la clave de API de OpenAI si no est√° definida.\n",
    "Entrada segura ‚Üí Solicita la clave de API de forma segura si es necesario.\n",
    "Inicializaci√≥n del modelo ‚Üí Carga un modelo de lenguaje (gpt-4o-mini) de OpenAI para su uso en LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7425d013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"ac√° va la clave\"\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4fd395",
   "metadata": {},
   "source": [
    "Este comando instala o actualiza silenciosamente (-qU) el paquete langchain-openai, que permite la integraci√≥n de modelos de OpenAI en LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdceea1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303d9b01",
   "metadata": {},
   "source": [
    "Carga la clave de API de OpenAI y crea una instancia de OpenAIEmbeddings para convertir texto en vectores usando el modelo text-embedding-3-large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a527542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f64a6f",
   "metadata": {},
   "source": [
    "Instalar o actualizar silenciosamente el paquete langchain-core, que contiene las funcionalidades principales de LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "313030eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce910ed",
   "metadata": {},
   "source": [
    "Crea un almac√©n de vectores en memoria utilizando los embeddings generados, permitiendo b√∫squedas eficientes de similitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "659ae200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb8badb",
   "metadata": {},
   "source": [
    "El c√≥digo carga y procesa el contenido de un blog, lo divide en fragmentos, los indexa en un vector store y luego implementa un sistema RAG. Este sistema recupera informaci√≥n relevante seg√∫n una pregunta, genera una respuesta con un modelo de lenguaje y ejecuta el flujo con un grafo de estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae835d06-f4fb-4492-b85f-a76a13e27e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento 1 (Primeros 200 caracteres):\n",
      "LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool con\n",
      "\n",
      "Documento 2 (Primeros 200 caracteres):\n",
      "Memory\n",
      "\n",
      "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
      "Long-term memory: This provides the agent with th\n",
      "\n",
      "Documento 3 (Primeros 200 caracteres):\n",
      "Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposit\n",
      "\n",
      "Documento 4 (Primeros 200 caracteres):\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts p\n",
      "\n",
      "Documento 5 (Primeros 200 caracteres):\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language \n",
      "\n",
      "Error al indexar en FAISS: 'ascii' codec can't encode character '\\xe1' in position 9: ordinal not in range(128)\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Cargar documentos desde la web\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# Dividir documentos en fragmentos\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# üîπ Asegurar codificaci√≥n UTF-8 y remover caracteres no imprimibles\n",
    "for doc in all_splits:\n",
    "    doc.page_content = (\n",
    "        doc.page_content.encode(\"utf-8\", \"ignore\").decode(\"utf-8\").strip()\n",
    "    )\n",
    "\n",
    "# üîπ Verificar que el contenido de los documentos es v√°lido\n",
    "for i, doc in enumerate(all_splits[:5]):  # Mostrar los primeros 5 documentos\n",
    "    print(f\"Documento {i+1} (Primeros 200 caracteres):\\n{doc.page_content[:200]}\\n\")\n",
    "\n",
    "# Inicializar FAISS correctamente\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "try:\n",
    "    vector_store = FAISS.from_documents(all_splits, embeddings)  # Crear FAISS aqu√≠\n",
    "    print(\"Documentos indexados correctamente en FAISS\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al indexar en FAISS: {e}\")\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "# Define application steps\n",
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "# Compile application and test\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379393bb",
   "metadata": {},
   "source": [
    "El c√≥digo carga el contenido de una p√°gina web, filtrando solo los t√≠tulos, encabezados y el contenido principal. Luego, verifica que solo se haya obtenido un documento y muestra la cantidad de caracteres de su contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c1f503d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43130\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71348d42",
   "metadata": {},
   "source": [
    "Se imprime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0a31e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a8e3fd",
   "metadata": {},
   "source": [
    "# Divisi√≥n\n",
    "\n",
    "Nuestro documento cargado tiene m√°s de 42 000 caracteres, lo cual es demasiado largo para caber en la ventana de contexto de muchos modelos. Incluso aquellos que pueden incluir la publicaci√≥n completa en su ventana de contexto pueden tener dificultades para encontrar informaci√≥n en entradas muy largas.\n",
    "\n",
    "Para solucionar esto, dividiremos el Documentarchivo en fragmentos para su incrustaci√≥n y almacenamiento vectorial. Esto deber√≠a permitirnos recuperar solo las partes m√°s relevantes de la entrada del blog en tiempo de ejecuci√≥n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0f22030e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 66 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf5cd5d",
   "metadata": {},
   "source": [
    "#Almacenamiento\n",
    "\n",
    "Esta l√≠nea agrega los fragmentos de texto al almac√©n vectorial y guarda sus identificadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fdb558fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, doc in enumerate(all_splits):\n",
    "    try:\n",
    "        doc.page_content.encode(\"utf-8\")  # Intentar codificaci√≥n\n",
    "    except UnicodeEncodeError:\n",
    "        print(f\"Error en documento {idx}: {doc.page_content}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa8946c",
   "metadata": {},
   "source": [
    "# Recuperaci√≥n y generaci√≥n\n",
    "\n",
    "El c√≥digo obtiene un prompt predefinido de LangChain Hub llamado \"rlm/rag-prompt\", lo invoca con un contexto y una pregunta de ejemplo, convierte la respuesta en mensajes y verifica que solo haya un mensaje antes de imprimir su contenido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c133681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef90bc9d",
   "metadata": {},
   "source": [
    "Define una estructura de datos (State) para almacenar la pregunta, el contexto y la respuesta en un sistema RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "759c5bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0d8036",
   "metadata": {},
   "source": [
    "Define dos funciones: retrieve, que busca documentos similares a la pregunta en el vector store, y generate, que usa esos documentos como contexto para generar una respuesta con el modelo de lenguaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "45b77802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c2d29d",
   "metadata": {},
   "source": [
    "Conectamos los pasos de recuperaci√≥n y generaci√≥n en una sola secuencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bb9838cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c712d90",
   "metadata": {},
   "source": [
    "Genera y muestra un diagrama en formato PNG del flujo del graph usando Mermaid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cad6e3d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fe12f1",
   "metadata": {},
   "source": [
    "Ejecuta el flujo del gr√°fico con la pregunta \"What is Task Decomposition?\", obtiene el contexto relevante y genera una respuesta, luego imprime ambos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c492de",
   "metadata": {},
   "source": [
    "Ejecuta el flujo del gr√°fico en modo de transmisi√≥n, mostrando actualizaciones paso a paso de la ejecuci√≥n del proceso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babe7e1a",
   "metadata": {},
   "source": [
    "Transmite los mensajes generados por el gr√°fico en tiempo real, imprimiendo el contenido de cada mensaje seguido de |."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d3d19e",
   "metadata": {},
   "source": [
    "# Personalizar el mensaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c6c5a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3154a528",
   "metadata": {},
   "source": [
    "# An√°lisis de consultas\n",
    "\n",
    "Emplea modelos para transformar o construir consultas de b√∫squeda optimizadas a partir de la informaci√≥n sin procesar del usuario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "34ac0a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
       " 'start_index': 8,\n",
       " 'section': 'beginning'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3\n",
    "\n",
    "for i, document in enumerate(all_splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "\n",
    "all_splits[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7925ac07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento 1 (Primeros 200 caracteres):\n",
      "LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool con\n",
      "\n",
      "Documento 2 (Primeros 200 caracteres):\n",
      "Memory\n",
      "\n",
      "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
      "Long-term memory: This provides the agent with th\n",
      "\n",
      "Documento 3 (Primeros 200 caracteres):\n",
      "Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposit\n",
      "\n",
      "Documento 4 (Primeros 200 caracteres):\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts p\n",
      "\n",
      "Documento 5 (Primeros 200 caracteres):\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language \n",
      "\n",
      "Error al indexar en FAISS: 'ascii' codec can't encode character '\\xe1' in position 9: ordinal not in range(128)\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "for i, doc in enumerate(all_splits[:5]):  # Mostrar los primeros 5 documentos\n",
    "    print(f\"Documento {i+1} (Primeros 200 caracteres):\\n{doc.page_content[:200]}\\n\")\n",
    "\n",
    "# Inicializar FAISS correctamente\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "try:\n",
    "    vector_store = FAISS.from_documents(all_splits, embeddings)  # Crear FAISS aqu√≠\n",
    "    print(\"Documentos indexados correctamente en FAISS\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al indexar en FAISS: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79addd0f",
   "metadata": {},
   "source": [
    "Define un diccionario tipado para representar una consulta de b√∫squeda con una pregunta y una secci√≥n espec√≠fica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3b10f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9a96a6",
   "metadata": {},
   "source": [
    "Generar una consulta a partir de la entrada sin procesar del usuario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "145467fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento 1 (Primeros 200 caracteres):\n",
      "LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool con\n",
      "\n",
      "Documento 2 (Primeros 200 caracteres):\n",
      "Memory\n",
      "\n",
      "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
      "Long-term memory: This provides the agent with th\n",
      "\n",
      "Documento 3 (Primeros 200 caracteres):\n",
      "Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposit\n",
      "\n",
      "Documento 4 (Primeros 200 caracteres):\n",
      "Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts p\n",
      "\n",
      "Documento 5 (Primeros 200 caracteres):\n",
      "Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language \n",
      "\n",
      "Error al indexar en FAISS: 'ascii' codec can't encode character '\\xe1' in position 9: ordinal not in range(128)\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import Annotated, List, TypedDict\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "\n",
    "# Update metadata (illustration purposes)\n",
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3\n",
    "\n",
    "for i, document in enumerate(all_splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "for i, doc in enumerate(all_splits[:5]):  # Mostrar los primeros 5 documentos\n",
    "    print(f\"Documento {i+1} (Primeros 200 caracteres):\\n{doc.page_content[:200]}\\n\")\n",
    "\n",
    "# Inicializar FAISS correctamente\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "try:\n",
    "    vector_store = FAISS.from_documents(all_splits, embeddings)  # Crear FAISS aqu√≠\n",
    "    print(\"Documentos indexados correctamente en FAISS\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al indexar en FAISS: {e}\")\n",
    "\n",
    "# Define schema for search\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\",\n",
    "    ]\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def analyze_query(state: State):\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    return {\"query\": query}\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c2101657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53256eb",
   "metadata": {},
   "source": [
    "# Herramientas utilizadas en este proyecto\n",
    "\n",
    "1. LangChain - Framework para construir aplicaciones con modelos de lenguaje.\n",
    "\n",
    "2. LangChain Hub - Repositorio de prompts predefinidos.\n",
    "\n",
    "3. LangChain Community - M√≥dulos adicionales como WebBaseLoader para cargar documentos web.\n",
    "\n",
    "4. LangChain Core - Componentes esenciales como Document y StateGraph.\n",
    "\n",
    "5. Pinecone - Base de datos vectorial para almacenar y recuperar documentos.\n",
    "\n",
    "6. OpenAI - Proveedor de embeddings y modelos de lenguaje.\n",
    "\n",
    "7. BeautifulSoup (bs4) - Para extraer contenido espec√≠fico de p√°ginas web.\n",
    "\n",
    "8. IPython.display - Para visualizar gr√°ficos generados con graph.draw_mermaid_png().\n",
    "\n",
    "9. Typing Extensions - Para definiciones avanzadas de tipos como TypedDict y Annotated.\n",
    "\n",
    "# Desarrollado por : Laura Valentina Rodr√≠guez Orteg√≥n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
